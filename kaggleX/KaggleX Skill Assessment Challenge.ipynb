{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T19:38:18.355566Z",
     "start_time": "2024-06-12T19:38:18.348180Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge"
   ],
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Processing and Feature Engineering",
   "id": "971d6a79d24ad0f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:56:47.810471Z",
     "start_time": "2024-06-12T19:56:47.668758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.set_index('id', inplace=True)\n",
    "# df.drop(\"clean_title\", axis=1, inplace=True)\n",
    "# # df.drop(\"Engine Displacement (L)\", axis=1, inplace=True)"
   ],
   "id": "f2cc441e61d47f84",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:56:57.882544Z",
     "start_time": "2024-06-12T19:56:57.874556Z"
    }
   },
   "cell_type": "code",
   "source": "df = df[['brand', 'model', 'model_year', 'milage', 'fuel_type', 'price']]",
   "id": "da91ef9254ed9cb1",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:56:59.237436Z",
     "start_time": "2024-06-12T19:56:59.201695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_engine_data(df, column_name='engine'):\n",
    "    \"\"\"\n",
    "    Preprocesses the engine data in the specified column of a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame containing the engine data.\n",
    "    column_name (str): The name of the column with the engine descriptions.\n",
    "    debug (bool): If True, prints the entries that fail regex match.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: The DataFrame with the original column replaced by structured columns.\n",
    "    \"\"\"\n",
    "       \n",
    "    # Prepare regex patterns for data extraction\n",
    "    hp_pattern = re.compile(r'(\\d+\\.\\d+|\\d+)\\s*HP', re.IGNORECASE)\n",
    "    disp_pattern = re.compile(r'(\\d+\\.\\d+|\\d+)L', re.IGNORECASE)\n",
    "    cyl_pattern = re.compile(r'(\\d+)\\s*Cylinder', re.IGNORECASE)\n",
    "    conf_pattern = re.compile(r'(I\\d+|V\\d+|Flat \\d+|Straight \\d+)', re.IGNORECASE)\n",
    "    turbo_pattern = re.compile(r'turbo', re.IGNORECASE)\n",
    "    technology_pattern = re.compile(r'DOHC|SOHC|MPFI|GDI|OHV|PDI', re.IGNORECASE)\n",
    "    \n",
    "    # Fuel patterns dictionary\n",
    "    fuel_patterns = {\n",
    "        'Gasoline': re.compile(r'Gasoline', re.IGNORECASE),\n",
    "        'Diesel': re.compile(r'Diesel', re.IGNORECASE),\n",
    "        'Hybrid': re.compile(r'Hybrid', re.IGNORECASE),\n",
    "        'Electric': re.compile(r'Electric', re.IGNORECASE),\n",
    "        'Flex Fuel': re.compile(r'Flex Fuel', re.IGNORECASE),\n",
    "        'Plug-In Electric/Gas': re.compile(r'Plug-In Electric/Gas', re.IGNORECASE)\n",
    "    }\n",
    "    \n",
    "    # Lists to hold extracted data\n",
    "    horsepower = []\n",
    "    displacement = []\n",
    "    cylinders = []\n",
    "    configuration = []\n",
    "    fuel_type = []\n",
    "    turbo = []\n",
    "    technology = []\n",
    "    \n",
    "    # Process each entry in the specified column\n",
    "    for desc in df[column_name]:\n",
    "        # Extract and append horsepower\n",
    "        hp_match = hp_pattern.search(desc)\n",
    "        horsepower.append(int(float(hp_match.group(1))) if hp_match else None)\n",
    "    \n",
    "        # Extract and append displacement\n",
    "        disp_match = disp_pattern.search(desc)\n",
    "        displacement.append(disp_match.group(1) if disp_match else None)\n",
    "    \n",
    "        # Extract and append cylinder count\n",
    "        cyl_match = cyl_pattern.search(desc)\n",
    "        cylinders.append(int(cyl_match.group(1)) if cyl_match else None)\n",
    "    \n",
    "        # Extract and append engine configuration\n",
    "        conf_match = conf_pattern.search(desc)\n",
    "        configuration.append(conf_match.group(1) if conf_match else None)\n",
    "    \n",
    "        # Determine and append fuel type\n",
    "        detected_fuel_type = None\n",
    "        for fuel, pattern in fuel_patterns.items():\n",
    "            if pattern.search(desc):\n",
    "                detected_fuel_type = fuel\n",
    "                break\n",
    "        fuel_type.append(detected_fuel_type if detected_fuel_type else 'Other')\n",
    "    \n",
    "        # Check and append turbo presence\n",
    "        turbo.append('Yes' if turbo_pattern.search(desc) else 'No')\n",
    "    \n",
    "        # Extract and append technology terms\n",
    "        tech_match = technology_pattern.findall(desc)\n",
    "        technology.append(\", \".join(tech_match) if tech_match else None)\n",
    "    \n",
    "    # Create a DataFrame from the lists\n",
    "    new_data = pd.DataFrame({\n",
    "        'Horsepower': horsepower,\n",
    "        'Engine Displacement (L)': displacement,\n",
    "        'Number of Cylinders': cylinders,\n",
    "        'Engine Configuration': configuration,\n",
    "        # 'Fuel Type': fuel_type,\n",
    "        # 'Turbo': turbo,\n",
    "        # 'Technology': technology\n",
    "    })\n",
    "    df.drop(column_name, axis=1, inplace=True)\n",
    "    # Concatenate the new data with the original DataFrame\n",
    "    return pd.concat([df, new_data], axis=1)"
   ],
   "id": "493dec0d5f1190c5",
   "outputs": [],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:56:59.645469Z",
     "start_time": "2024-06-12T19:56:59.637232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_transmission_data(df, column_name='transmission'):\n",
    "    # Regex pattern to extract number of speeds and type of transmission\n",
    "    pattern = re.compile(r'(\\d+)-Speed\\s+(M/T|A/T)', re.IGNORECASE)\n",
    "    \n",
    "    # Lists to hold extracted data\n",
    "    num_speeds = []\n",
    "    transmission_type = []\n",
    "    \n",
    "    # Process each entry in the specified column\n",
    "    for entry in df[column_name]:\n",
    "        match = pattern.search(entry)\n",
    "        if match:\n",
    "            # Append the number of speeds and transmission type if pattern matches\n",
    "            num_speeds.append(int(match.group(1)))\n",
    "            transmission_type.append(match.group(2))\n",
    "        else:\n",
    "            # Handle entries that do not match the pattern\n",
    "            num_speeds.append(None)\n",
    "            transmission_type.append(None)\n",
    "    \n",
    "    # Add the extracted data as new columns in the DataFrame\n",
    "    # df['Number of Speeds'] = num_speeds\n",
    "    df['Transmission Type'] = transmission_type\n",
    "    df.drop(column_name, axis=1, inplace=True)\n",
    "    return df"
   ],
   "id": "242c4df54e526023",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:59:11.354332Z",
     "start_time": "2024-06-12T19:59:11.345583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_data(df):\n",
    "    # Drop rows where the target (price) is missing\n",
    "    df.dropna(subset=[\"price\"], inplace=True)\n",
    "    df['model_year'] = pd.to_datetime(df['model_year'], format='%Y')\n",
    "    \n",
    "    # Selecting features: Here we should focus on features that are numeric and categorical columns that need encoding\n",
    "    numeric_features = ['milage']\n",
    "                        # 'Horsepower', 'Number of Cylinders']\n",
    "    categorical_features = ['brand', 'model', 'fuel_type', 'model_year']\n",
    "                            # 'Transmission Type', ]\n",
    "    \n",
    "    # Creating transformers for numerical and categorical data\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    # Combine transformers into a preprocessor step\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "    \n",
    "    return preprocessor"
   ],
   "id": "a46b14455a771c0c",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:59:11.951688Z",
     "start_time": "2024-06-12T19:59:11.946842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df = preprocess_engine_data(df)\n",
    "# df = preprocess_transmission_data(df)"
   ],
   "id": "2bd902949b4ed289",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training",
   "id": "88597bea025bda07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:59:13.238435Z",
     "start_time": "2024-06-12T19:59:13.229459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(df, preprocessor, m= Ridge()):\n",
    "    X = df.drop('price', axis=1)\n",
    "    y = df['price']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', m)  # Using Ridge regression with default alpha\n",
    "    ])\n",
    "    \n",
    "    param_grid = {'regressor__alpha': [0.1, 1.0, 10.0]}  # Hyperparameter tuning for Ridge\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    return best_model, rmse\n"
   ],
   "id": "10939e96da8ce9e6",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Linear regression",
   "id": "e071200b686141b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:59:22.167495Z",
     "start_time": "2024-06-12T19:59:15.057034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main function to run the whole process\n",
    "# def main(df):\n",
    "#     preprocessor = preprocess_data(df)\n",
    "#     model = LinearRegression() \n",
    "#     model = Ridge() # Starting with a simple linear regression model\n",
    "#     clf, rmse, features  = train_model(df, preprocessor, model)\n",
    "#     print(f\"Root Mean Squared Error: {rmse}\")\n",
    "#     print(\"Feature Importances (if applicable):\")\n",
    "#     print(features)\n",
    "#     return [model, rmse, clf]\n",
    "\n",
    "def main(df):\n",
    "    preprocessor = preprocess_data(df)\n",
    "    clf, rmse = train_model(df, preprocessor)\n",
    "    print(f\"Root Mean Squared Error: {rmse}\")\n",
    "    return clf, rmse\n",
    "\n",
    "# Example usage (assuming df is your DataFrame)\n",
    "clf, rmse = main(df)\n",
    "\n",
    "# trained = main(df)\n",
    "# model = trained[0]\n",
    "# clf = trained[2]\n",
    "# print(trained[1])\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "test = preprocess_engine_data(test)\n",
    "test = preprocess_transmission_data(test)\n",
    "\n",
    "test['price'] = clf.predict(test)\n",
    "test['price'] = test['price'].round(3)\n",
    "test[['id', 'price']].to_csv('submission.csv', index=False)\n",
    "# 50993\n",
    "#50224.33"
   ],
   "id": "ee6b6a34f1e5edba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shami\\AppData\\Local\\Temp\\ipykernel_7960\\2628457459.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=[\"price\"], inplace=True)\n",
      "C:\\Users\\shami\\AppData\\Local\\Temp\\ipykernel_7960\\2628457459.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model_year'] = pd.to_datetime(df['model_year'], format='%Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 48424.563600782305\n"
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Decision tree",
   "id": "232227ef60cffe49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:59:30.795101Z",
     "start_time": "2024-06-12T19:59:30.776227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(df, preprocessor, model):\n",
    "    X = df.drop('price', axis=1)\n",
    "    y = df['price']\n",
    "    # print(X.info())\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('regressor', model)])\n",
    "\n",
    "    # Setup Grid Search Parameters\n",
    "    param_grid = {\n",
    "        'regressor__max_depth': [None, 10, 20, 30],\n",
    "        'regressor__min_samples_split': [2, 10, 20],\n",
    "        'regressor__min_samples_leaf': [1, 5, 10]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_clf = grid_search.best_estimator_\n",
    "\n",
    "    if hasattr(best_clf.named_steps['regressor'], 'feature_importances_'):\n",
    "        feature_names = get_feature_names(best_clf.named_steps['preprocessor'])\n",
    "        feature_importances = best_clf.named_steps['regressor'].feature_importances_\n",
    "        features = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': feature_importances\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "    else:\n",
    "        features = pd.DataFrame(columns=['Feature', 'Importance'])\n",
    "\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return best_clf, rmse, features\n",
    "\n",
    "def main(df):\n",
    "    preprocessor = preprocess_data(df)\n",
    "    model = DecisionTreeRegressor(random_state=42)\n",
    "    clf, rmse, features = train_model(df, preprocessor, model)\n",
    "    print(f\"Root Mean Squared Error with Decision Tree: {rmse}\")\n",
    "\n",
    "    return [model, rmse, clf]\n"
   ],
   "id": "eee62fb6ecf7c879",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T20:02:55.518779Z",
     "start_time": "2024-06-12T19:59:32.017386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trained = main(df)\n",
    "model = trained[0]\n",
    "clf = trained[2]\n",
    "print(trained[1])\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "test = preprocess_engine_data(test)\n",
    "test = preprocess_transmission_data(test)\n",
    "\n",
    "test['price'] = clf.predict(test)\n",
    "test['price'] = test['price'].round(3)\n",
    "test[['id', 'price']].to_csv('submission.csv',index=False)"
   ],
   "id": "52c968dc1234be48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error with Decision Tree: 52572.412067574725\n",
      "52572.412067574725\n"
     ]
    }
   ],
   "execution_count": 142
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random Forrest",
   "id": "63294f5671326e4d"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-12T20:02:55.520823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main(df):\n",
    "    preprocessor = preprocess_data(df)\n",
    "    model = RandomForestRegressor(random_state=42)  # Using a Random Forest Regressor\n",
    "    clf, rmse, features = train_model(df, preprocessor, model)\n",
    "    print(f\"Root Mean Squared Error with Random Forest: {rmse}\")\n",
    "  \n",
    "    return [model, rmse, clf]\n",
    "\n",
    "# Assuming df is your training DataFrame\n",
    "trained = main(df)\n",
    "model = trained[0]\n",
    "clf = trained[2]\n",
    "print(trained[1])\n",
    "\n",
    "# Load and preprocess test data\n",
    "test = pd.read_csv('test.csv')\n",
    "# Assuming preprocess_engine_data and preprocess_transmission_data are applicable and defined correctly\n",
    "test = preprocess_engine_data(test)  # Make sure this function is defined and operates correctly\n",
    "test = preprocess_transmission_data(test)  # Make sure this function is defined and operates correctly\n",
    "\n",
    "# Predict using the trained clf (pipeline with preprocessor and regressor)\n",
    "test['price'] = clf.predict(test)\n",
    "test['price'] = test['price'].round(3)\n",
    "test[['id', 'price']].to_csv('submission.csv', index=False)"
   ],
   "id": "1da0fc6062bc3a11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "48e6a661c1f894de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
