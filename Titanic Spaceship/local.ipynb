{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-10T12:24:00.338675Z",
     "start_time": "2024-10-10T12:24:00.120921Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Functions",
   "id": "7ed04e339720cba3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:55:31.244851Z",
     "start_time": "2024-10-10T12:55:31.193753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_missing_values(data):\n",
    "    \"\"\"\n",
    "    Check for missing values in the dataset.\n",
    "    \"\"\"\n",
    "    missing_values = data.isnull().sum()\n",
    "    return missing_values[missing_values > 0]\n",
    "\n",
    "def fill_missing_values(data):\n",
    "    \"\"\"\n",
    "    Fill missing values in the dataset.\n",
    "    - Drop rows with missing values in critical columns.\n",
    "    - Fill categorical columns with the mode.\n",
    "    - Fill numerical columns with the median.\n",
    "    \"\"\"\n",
    "    # Drop rows with missing values in critical columns\n",
    "    data = data.dropna(subset=['HomePlanet', 'CryoSleep', 'Cabin', 'Destination'])\n",
    "\n",
    "    # Fill missing categorical values with the mode\n",
    "    for column in ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', 'Name']:\n",
    "        data[column].fillna(data[column].mode()[0], inplace=True)\n",
    "\n",
    "    # Fill missing numerical values with the median\n",
    "    for column in ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']:\n",
    "        data[column].fillna(data[column].median(), inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def feature_engineering(data):\n",
    "    \"\"\"\n",
    "    Perform feature engineering on the dataset.\n",
    "    - Split 'Cabin' into 'Deck', 'CabinNumber', and 'Side'.\n",
    "    - Create 'TotalSpend' feature.\n",
    "    - Create 'AgeGroup' feature.\n",
    "    \"\"\"\n",
    "    # Split 'Cabin' into 'Deck', 'CabinNumber', and 'Side'\n",
    "    data[['Deck', 'CabinNumber', 'Side']] = data['Cabin'].astype(str).str.split('/', expand=True)\n",
    "    data['CabinNumber'] = pd.to_numeric(data['CabinNumber'], errors='coerce')\n",
    "    data = data.drop(columns=['Cabin'])\n",
    "\n",
    "    # Create 'TotalSpend' feature\n",
    "    data['TotalSpend'] = (\n",
    "        data['RoomService'] +\n",
    "        data['FoodCourt'] +\n",
    "        data['ShoppingMall'] +\n",
    "        data['Spa'] +\n",
    "        data['VRDeck']\n",
    "    )\n",
    "\n",
    "    # Create age groups\n",
    "    bins = [0, 12, 18, 35, 60, 100]\n",
    "    labels = ['Child', 'Teen', 'YoungAdult', 'Adult', 'Senior']\n",
    "    data['AgeGroup'] = pd.cut(data['Age'], bins=bins, labels=labels)\n",
    "\n",
    "    return data\n",
    "\n",
    "def encode_categorical_features(data):\n",
    "    \"\"\"\n",
    "    Encode categorical features using LabelEncoder.\n",
    "    \"\"\"\n",
    "    label_encoder = LabelEncoder()\n",
    "    for column in ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Name', 'Deck', 'Side', 'AgeGroup']:\n",
    "        data[column] = label_encoder.fit_transform(data[column].astype(str))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def check_target_balance(data, target_column):\n",
    "    \"\"\"\n",
    "    Check the balance of the target variable.\n",
    "    \"\"\"\n",
    "    target_balance = data[target_column].value_counts(normalize=True)\n",
    "    return target_balance\n",
    "\n",
    "def preprocess_data(data, target_column='Transported'):\n",
    "    \"\"\"\n",
    "    Perform the full preprocessing pipeline on the dataset.\n",
    "    \"\"\"\n",
    "    # Step 1: Check and fill missing values\n",
    "    data = fill_missing_values(data)\n",
    "\n",
    "    # Step 2: Perform feature engineering\n",
    "    data = feature_engineering(data)\n",
    "\n",
    "    # Step 3: Encode categorical variables\n",
    "    data = encode_categorical_features(data)\n",
    "\n",
    "    # Step 4: Check target variable balance\n",
    "    target_balance = check_target_balance(data, target_column)\n",
    "    print(\"Target Balance:\\n\", target_balance)\n",
    "\n",
    "    return data\n",
    "\n",
    "check_missing_values(spaceship_data)\n",
    "spaceship_data = preprocess_data(spaceship_data)"
   ],
   "id": "c04c8057ab9218b3",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:55:34.107209Z",
     "start_time": "2024-10-10T12:55:33.965797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = 'train.csv'\n",
    "spaceship_data = pd.read_csv(file_path)\n",
    "print(len(spaceship_data))\n",
    "spaceship_data.head()"
   ],
   "id": "5c6f0d1d4c5cde9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data wrangling\n",
    "1. Check missing values"
   ],
   "id": "a9d58c4a6b7080c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T13:03:38.187852Z",
     "start_time": "2024-10-10T13:03:38.167072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_values = spaceship_data.isnull().sum()\n",
    "missing_values[missing_values > 0]"
   ],
   "id": "9cbe4d4c6e969e6f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgeGroup    166\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Fill in/ drop missing values",
   "id": "978ff2d4bddf309c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:25:27.730628Z",
     "start_time": "2024-10-10T11:25:27.690318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spaceship_data = spaceship_data.dropna(subset=['HomePlanet', 'CryoSleep', 'Cabin', 'Destination'])\n",
    "\n",
    "# Fill missing categorical values with the mode\n",
    "for column in ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', 'Name']:\n",
    "    spaceship_data[column].fillna(spaceship_data[column].mode()[0], inplace=True)\n",
    "\n",
    "# Fill missing numerical values with the median\n",
    "for column in ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']:\n",
    "    spaceship_data[column].fillna(spaceship_data[column].median(), inplace=True)\n",
    "\n",
    "missing_values_after = spaceship_data.isnull().sum()\n",
    "missing_values_after[missing_values_after > 0]\n"
   ],
   "id": "71456c8b864574ab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shami\\AppData\\Local\\Temp\\ipykernel_10392\\2796621290.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  spaceship_data[column].fillna(spaceship_data[column].mode()[0], inplace=True)\n",
      "C:\\Users\\shami\\AppData\\Local\\Temp\\ipykernel_10392\\2796621290.py:5: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  spaceship_data[column].fillna(spaceship_data[column].mode()[0], inplace=True)\n",
      "C:\\Users\\shami\\AppData\\Local\\Temp\\ipykernel_10392\\2796621290.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  spaceship_data[column].fillna(spaceship_data[column].median(), inplace=True)\n",
      "C:\\Users\\shami\\AppData\\Local\\Temp\\ipykernel_10392\\2796621290.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  spaceship_data[column].fillna(spaceship_data[column].median(), inplace=True)\n",
      "C:\\Users\\shami\\AppData\\Local\\Temp\\ipykernel_10392\\2796621290.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  spaceship_data[column].fillna(spaceship_data[column].median(), inplace=True)\n",
      "C:\\Users\\shami\\AppData\\Local\\Temp\\ipykernel_10392\\2796621290.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  spaceship_data[column].fillna(spaceship_data[column].median(), inplace=True)\n",
      "C:\\Users\\shami\\AppData\\Local\\Temp\\ipykernel_10392\\2796621290.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  spaceship_data[column].fillna(spaceship_data[column].median(), inplace=True)\n",
      "C:\\Users\\shami\\AppData\\Local\\Temp\\ipykernel_10392\\2796621290.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  spaceship_data[column].fillna(spaceship_data[column].median(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Feature engineering (improves random forrest model from 78% to 80%)",
   "id": "8e98965e32d99ede"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:25:29.632872Z",
     "start_time": "2024-10-10T11:25:29.602855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Splitting the 'Cabin' into  'Deck', 'CabinNumber', and 'Side'\n",
    "spaceship_data[['Deck', 'CabinNumber', 'Side']] = spaceship_data['Cabin'].astype(str).str.split('/', expand=True)\n",
    "spaceship_data['CabinNumber'] = pd.to_numeric(spaceship_data['CabinNumber'], errors='coerce')\n",
    "spaceship_data = spaceship_data.drop(columns=['Cabin'])\n",
    "\n",
    "# 'TotalSpend' feature  (RoomService, FoodCourt, ShoppingMall, Spa, and VRDeck)\n",
    "spaceship_data['TotalSpend'] = (\n",
    "    spaceship_data['RoomService'] +\n",
    "    spaceship_data['FoodCourt'] +\n",
    "    spaceship_data['ShoppingMall'] +\n",
    "    spaceship_data['Spa'] +\n",
    "    spaceship_data['VRDeck']\n",
    ")\n",
    "\n",
    "# Create age groups\n",
    "bins = [0, 12, 18, 35, 60, 100]\n",
    "labels = ['Child', 'Teen', 'YoungAdult', 'Adult', 'Senior']\n",
    "spaceship_data['AgeGroup'] = pd.cut(spaceship_data['Age'], bins=bins, labels=labels)\n"
   ],
   "id": "f9d72439e2c4789a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Check target variable balance",
   "id": "4944f86c38539ef5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:32:53.584873Z",
     "start_time": "2024-10-10T11:32:53.574916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the balance of the target variable 'Transported'\n",
    "target_balance = spaceship_data['Transported'].value_counts(normalize=True)\n",
    "target_balance\n"
   ],
   "id": "5135644b5bfd9c1e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transported\n",
       "True     0.503914\n",
       "False    0.496086\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Encode categorical variables",
   "id": "2240116b326f0479"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:25:40.244153Z",
     "start_time": "2024-10-10T11:25:40.195632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_encoder = LabelEncoder()\n",
    "for column in ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Name', 'Deck', 'Side', 'AgeGroup']:\n",
    "    spaceship_data[column] = label_encoder.fit_transform(spaceship_data[column])\n",
    "spaceship_data.head()"
   ],
   "id": "523c76c80fa7675d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  PassengerId  HomePlanet  CryoSleep  Destination   Age  VIP  RoomService  \\\n",
       "0     0001_01           1          0            2  39.0    0          0.0   \n",
       "1     0002_01           0          0            2  24.0    0        109.0   \n",
       "2     0003_01           1          0            2  58.0    1         43.0   \n",
       "3     0003_02           1          0            2  33.0    0          0.0   \n",
       "4     0004_01           0          0            2  16.0    0        303.0   \n",
       "\n",
       "   FoodCourt  ShoppingMall     Spa  VRDeck  Name  Transported  Deck  \\\n",
       "0        0.0           0.0     0.0     0.0  4794        False     1   \n",
       "1        9.0          25.0   549.0    44.0  4109         True     5   \n",
       "2     3576.0           0.0  6715.0    49.0   412        False     0   \n",
       "3     1283.0         371.0  3329.0   193.0  6503        False     0   \n",
       "4       70.0         151.0   565.0     2.0  7583         True     5   \n",
       "\n",
       "   CabinNumber  Side  TotalSpend  AgeGroup  \n",
       "0            0     0         0.0         0  \n",
       "1            0     1       736.0         4  \n",
       "2            0     1     10383.0         0  \n",
       "3            0     1      5176.0         4  \n",
       "4            1     1      1091.0         3  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Deck</th>\n",
       "      <th>CabinNumber</th>\n",
       "      <th>Side</th>\n",
       "      <th>TotalSpend</th>\n",
       "      <th>AgeGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4794</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4109</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>736.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>412</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>6503</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7583</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Split train and test data",
   "id": "6c4bc65c30dd0362"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:25:41.541335Z",
     "start_time": "2024-10-10T11:25:41.529071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the dataset into features and target\n",
    "X = spaceship_data.drop(columns=['PassengerId', 'Transported'])\n",
    "y = spaceship_data['Transported']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "a2ceff7880b0ceef",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Models \n",
    "1. Random forrest "
   ],
   "id": "fba97373a8a43b9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:42:54.015424Z",
     "start_time": "2024-10-10T11:39:12.235347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the parameter grid for RandomForest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to find the best parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "report_best = classification_report(y_test, y_pred_best)\n",
    "best_params, accuracy_best, report_best"
   ],
   "id": "1da27145c8d6fff9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "324 fits failed out of a total of 972.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "255 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "69 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.78693182 0.78882576 0.79434975\n",
      " 0.79387626 0.79292929 0.79766414 0.79498106 0.79545455 0.79182449\n",
      " 0.79482323 0.7957702  0.79434975 0.79498106 0.79434975 0.79482323\n",
      " 0.79782197 0.79655934 0.79703283 0.79529672 0.79419192 0.79561237\n",
      " 0.79529672 0.79419192 0.79561237 0.79592803 0.79671717 0.79845328\n",
      " 0.78693182 0.78882576 0.79434975 0.79387626 0.79292929 0.79766414\n",
      " 0.79498106 0.79545455 0.79182449 0.79482323 0.7957702  0.79434975\n",
      " 0.79498106 0.79434975 0.79482323 0.79782197 0.79655934 0.79703283\n",
      " 0.79529672 0.79419192 0.79561237 0.79529672 0.79419192 0.79561237\n",
      " 0.79592803 0.79671717 0.79845328        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.79182449 0.79387626 0.7946654  0.79356061 0.79624369 0.79482323\n",
      " 0.7946654  0.79371843 0.7946654  0.79498106 0.79513889 0.79640152\n",
      " 0.79513889 0.79371843 0.7957702  0.79498106 0.79324495 0.79655934\n",
      " 0.79450758 0.79450758 0.79640152 0.79450758 0.79450758 0.79640152\n",
      " 0.79592803 0.79782197 0.796875   0.79182449 0.79387626 0.7946654\n",
      " 0.79356061 0.79624369 0.79482323 0.7946654  0.79371843 0.7946654\n",
      " 0.79498106 0.79513889 0.79640152 0.79513889 0.79371843 0.7957702\n",
      " 0.79498106 0.79324495 0.79655934 0.79450758 0.79450758 0.79640152\n",
      " 0.79450758 0.79450758 0.79640152 0.79592803 0.79782197 0.796875\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.78866793 0.79056187 0.79403409\n",
      " 0.79434975 0.79861111 0.79845328 0.79608586 0.79419192 0.79482323\n",
      " 0.7946654  0.79561237 0.79450758 0.79782197 0.79529672 0.79592803\n",
      " 0.7979798  0.79940025 0.79671717 0.79498106 0.79340278 0.79640152\n",
      " 0.79498106 0.79340278 0.79640152 0.79671717 0.79640152 0.79955808\n",
      " 0.78866793 0.79056187 0.79403409 0.79434975 0.79861111 0.79845328\n",
      " 0.79608586 0.79419192 0.79482323 0.7946654  0.79561237 0.79450758\n",
      " 0.79782197 0.79529672 0.79592803 0.7979798  0.79940025 0.79671717\n",
      " 0.79498106 0.79340278 0.79640152 0.79498106 0.79340278 0.79640152\n",
      " 0.79671717 0.79640152 0.79955808        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.78693182 0.78929924 0.7946654  0.79387626 0.79229798 0.79750631\n",
      " 0.79498106 0.79545455 0.79198232 0.79482323 0.7957702  0.79434975\n",
      " 0.79498106 0.79434975 0.79482323 0.79782197 0.79655934 0.79703283\n",
      " 0.79529672 0.79419192 0.79561237 0.79529672 0.79419192 0.79561237\n",
      " 0.79592803 0.79671717 0.79845328 0.78693182 0.78929924 0.7946654\n",
      " 0.79387626 0.79229798 0.79750631 0.79498106 0.79545455 0.79198232\n",
      " 0.79482323 0.7957702  0.79434975 0.79498106 0.79434975 0.79482323\n",
      " 0.79782197 0.79655934 0.79703283 0.79529672 0.79419192 0.79561237\n",
      " 0.79529672 0.79419192 0.79561237 0.79592803 0.79671717 0.79845328]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 20,\n",
       "  'max_features': 'sqrt',\n",
       "  'min_samples_leaf': 4,\n",
       "  'min_samples_split': 10,\n",
       "  'n_estimators': 200},\n",
       " 0.8005050505050505,\n",
       " '              precision    recall  f1-score   support\\n\\n       False       0.80      0.80      0.80       794\\n        True       0.80      0.80      0.80       790\\n\\n    accuracy                           0.80      1584\\n   macro avg       0.80      0.80      0.80      1584\\nweighted avg       0.80      0.80      0.80      1584\\n')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Ensemble methods (Stacking), improved from 80% to 80.36%",
   "id": "d05e025c73c3a1c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:48:12.296340Z",
     "start_time": "2024-10-10T12:48:02.814225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "report_gb = classification_report(y_test, y_pred_gb)\n",
    "\n",
    "# 2. XGBoost\n",
    "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "report_xgb = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "# 3. Stacking Classifier\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
    "    ('xgb', XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "]\n",
    "stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=3)\n",
    "stacking_model.fit(X_train, y_train)\n",
    "y_pred_stack = stacking_model.predict(X_test)\n",
    "accuracy_stack = accuracy_score(y_test, y_pred_stack)\n",
    "report_stack = classification_report(y_test, y_pred_stack)\n",
    "\n",
    "# Results\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_gb)\n",
    "print(report_gb)\n",
    "print(\"XGBoost Accuracy:\", accuracy_xgb)\n",
    "print(report_xgb)\n",
    "print(\"Stacking Classifier Accuracy:\", accuracy_stack)\n",
    "print(report_stack)"
   ],
   "id": "f32134a82800aca9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:48:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:48:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:48:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:48:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\shami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:48:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.797979797979798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.78      0.79       794\n",
      "        True       0.79      0.82      0.80       790\n",
      "\n",
      "    accuracy                           0.80      1584\n",
      "   macro avg       0.80      0.80      0.80      1584\n",
      "weighted avg       0.80      0.80      0.80      1584\n",
      "\n",
      "XGBoost Accuracy: 0.7954545454545454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.78      0.79       794\n",
      "        True       0.78      0.81      0.80       790\n",
      "\n",
      "    accuracy                           0.80      1584\n",
      "   macro avg       0.80      0.80      0.80      1584\n",
      "weighted avg       0.80      0.80      0.80      1584\n",
      "\n",
      "Stacking Classifier Accuracy: 0.8036616161616161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.79      0.80       794\n",
      "        True       0.80      0.81      0.81       790\n",
      "\n",
      "    accuracy                           0.80      1584\n",
      "   macro avg       0.80      0.80      0.80      1584\n",
      "weighted avg       0.80      0.80      0.80      1584\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
